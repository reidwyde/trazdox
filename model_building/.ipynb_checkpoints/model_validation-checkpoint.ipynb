{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "### Hypothesis: the model that simulated the data will be the model that best fits it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from theano.compile.ops import as_op\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "# This makes the plots appear inside the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "dirname = os.getcwd()\n",
    "filename = dirname + '\\..\\data\\\\tumor_size_db.csv'\n",
    "tumor_size_db = pd.read_csv(filename)\n",
    "tumor_size_db.head()\n",
    "\n",
    "ts = np.array(tumor_size_db['Day']).reshape(-1,1)\n",
    "Ts = np.array(tumor_size_db[['G1_avg','G2_avg','G3_avg','G4_avg','G5_avg','G6_avg']]).transpose() # indexing: group, time\n",
    "sigmas = np.array(tumor_size_db[['G1_sd','G2_sd','G3_sd','G4_sd','G5_sd','G6_sd']]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment\n",
    "\n",
    "def unit(x):\n",
    "    if x>=0: return 1\n",
    "    return 0\n",
    "\n",
    "def get_tt(tuple_treatment_group):\n",
    "    switcher={\n",
    "        ('dox',2): [39],\n",
    "        \n",
    "        ('her',3): [35,38],\n",
    "        \n",
    "        ('dox',4): [35],\n",
    "        ('her',4): [36,39],\n",
    "        \n",
    "        ('her',5): [35,38],\n",
    "        ('dox',5): [39],\n",
    "        \n",
    "        ('her',6): [35,38],\n",
    "        ('dox',6): [35,38]\n",
    "    }  \n",
    "    return switcher.get(tuple_treatment_group, [])\n",
    "\n",
    "\n",
    "def treatment_inst(delta, T, tau, t, treatment_times):\n",
    "    if len(treatment_times) == 0: return 0\n",
    "    S = 0\n",
    "    for tt in treatment_times:\n",
    "        if unit(t-tt-0.0001):\n",
    "            S = S + delta*np.exp(-tau*(t-tt)) \n",
    "        if math.isnan(S): \n",
    "            print('nan treatment')\n",
    "            print('tau*(t-tt) ' + str(tau*(t-tt)))\n",
    "            print('T: ' + str(T))\n",
    "            print('t: ' + str(t))\n",
    "            print('tt: ' + str(tt))\n",
    "            print('tau: ' + str(tau))\n",
    "    return S\n",
    "\n",
    "def dox_treatment_inst(delta, T, tau, t, group_idx):\n",
    "    treatment_times = get_tt(('dox',group_idx+1))\n",
    "    return treatment_inst(delta, T, tau, t, treatment_times)\n",
    "    \n",
    "def her_treatment_inst(delta, T, tau, t, group_idx):\n",
    "    treatment_times = get_tt(('her', group_idx+1))\n",
    "    return treatment_inst(delta, T, tau, t, treatment_times)\n",
    "\n",
    "def dox_treatment_all_inst(delta, T_all, tau, t):\n",
    "    Sd = np.zeros((6,))\n",
    "    for group in range(6):\n",
    "        T = T_all[group]\n",
    "        Sd[group] = dox_treatment_inst(delta, T, tau, t, group)\n",
    "    return Sd\n",
    "\n",
    "def her_treatment_all_inst(delta, T_all, tau, t):\n",
    "    Sh = np.zeros((6,))\n",
    "    for group in range(6):\n",
    "        T = T_all[group]\n",
    "        Sh[group] = her_treatment_inst(delta, T, tau, t, group)\n",
    "    return Sh\n",
    "\n",
    "\n",
    "# Graphing\n",
    "\n",
    "\n",
    "def graph_sim(sim_times, T_sim):\n",
    "    plt.figure(figsize=[16,10])\n",
    "    for ii in range(6):\n",
    "        plt.subplot(2,3,ii+1)\n",
    "        #plt.scatter(tumor_size_db['Day'], tumor_size_db['G'+str(ii+1)+'_avg'])\n",
    "        plt.errorbar(tumor_size_db['Day'], Ts[ii], sigmas[ii],fmt='.',capsize=2)\n",
    "        plt.plot(sim_times, T_sim[ii])\n",
    "        plt.title('G' + str(ii+1))\n",
    "        plt.xlabel('Day')\n",
    "        plt.ylabel('Size')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def graph_dox(sim_times, dox):\n",
    "    plt.figure(figsize=[16,10])\n",
    "    for ii in range(6):\n",
    "        plt.subplot(2,3,ii+1)\n",
    "        #plt.scatter(tumor_size_db['Day'], tumor_size_db['G'+str(ii+1)+'_avg'])\n",
    "        plt.plot(sim_times, dox[ii])\n",
    "        plt.title('Dox ' + str(ii+1))\n",
    "        plt.xlabel('Day')\n",
    "        plt.ylabel('amt')\n",
    "    plt.show()\n",
    "    \n",
    "def graph_her(sim_times, her):\n",
    "    plt.figure(figsize=[16,10])\n",
    "    for ii in range(6):\n",
    "        plt.subplot(2,3,ii+1)\n",
    "        #plt.scatter(tumor_size_db['Day'], tumor_size_db['G'+str(ii+1)+'_avg'])\n",
    "        plt.plot(sim_times, her[ii])\n",
    "        plt.title('her ' + str(ii+1))\n",
    "        plt.xlabel('Day')\n",
    "        plt.ylabel('amt')\n",
    "    plt.show()\n",
    "\n",
    "# Model Building\n",
    "\n",
    "def rungeKutta(ts, T0, dTdt, params): \n",
    "    time_len = len(ts.ravel())\n",
    "    ret = np.zeros((6, time_len))\n",
    "    ret[:,0] = T0\n",
    "    T = T0\n",
    "    for i in range(1,time_len):\n",
    "        T = T.clip(min=0)\n",
    "        t0 = ts[i-1]\n",
    "        t = ts[i]\n",
    "        h = t-t0 \n",
    "        k1 = h * dTdt(t, T, params) \n",
    "        k2 = h * dTdt(t+0.5*h, T + 0.5 * k1, params) \n",
    "        k3 = h * dTdt(t+0.5*h, T + 0.5 * k2, params) \n",
    "        k4 = h * dTdt(t+h, T + k3, params) \n",
    "        T = T + (1.0 / 6.0)*(k1 + 2 * k2 + 2 * k3 + k4) \n",
    "        if np.float('-inf') in T: \n",
    "            print('divergence in rk')\n",
    "            print('t0 ' + str(t0))\n",
    "            print('t ' + str(t))\n",
    "            print('h ' + str(h))\n",
    "            print('k1 ' + str(k1))\n",
    "            print('k2 ' + str(k2))\n",
    "            print('k3 ' + str(k3))\n",
    "            print('k4 '  + str(k4))\n",
    "            print('T ' + str(T))\n",
    "        ret[:,i] = T.clip(min=0)\n",
    "    return ret\n",
    "\n",
    "class growth_model(object):\n",
    "    def __init__(self, times, T0):\n",
    "        self._times = times\n",
    "        self._T0 = T0\n",
    "\n",
    "    def _simulate(self, params, times):\n",
    "        #values = odeint(self.dydt, self._y0[0], times, (params,),rtol=1e-6,atol=1e-6)\n",
    "        values = rungeKutta(times, self._T0, self.dTdt, params)\n",
    "\n",
    "        return values\n",
    "   \n",
    "    def get_param(self, param_name, n=50):\n",
    "        return sum(self.trace[param_name][-n:])/n\n",
    "\n",
    "    def get_treatment_params(self):\n",
    "        delta_d = self.get_param('delta_d')\n",
    "        delta_h = self.get_param('delta_h')\n",
    "        tau_d = self.get_param('tau_d')\n",
    "        tau_h = self.get_param('tau_h')\n",
    "        return [delta_d, delta_h, tau_d, tau_h]\n",
    "    \n",
    "sim_times = np.linspace(7,70,70-7+1)\n",
    "\n",
    "\n",
    "\n",
    "def fit_sim_graph_model(model_class):\n",
    "    this_model = model_class(ts, Ts[:,0])\n",
    "    this_model.backward(Ts, sigmas)\n",
    "    #delta_d, delta_h, tau_d, tau_h = this_model.get_treatment_params()\n",
    "    #T_sim = this_model.simulate([this_model.get_param(x) for x in this_model.param_list])\n",
    "    \n",
    "    r, delta_d, delta_h, tau_d, tau_h= [this_model.get_param(x) for x in this_model.param_list]\n",
    "    T_sim = this_model.simulate(r, delta_d, delta_h, tau_d, tau_h, sim_times)\n",
    "    \n",
    "    dox = np.zeros((6,len(sim_times.ravel())))\n",
    "    her = np.zeros((6,len(sim_times.ravel())))\n",
    "    for ii in range(len(sim_times)):\n",
    "        T = T_sim[:,ii]\n",
    "        t = sim_times[ii]\n",
    "        dox[:,ii] = dox_treatment_all_inst(delta_d, T, tau_d, t)\n",
    "        her[:,ii] = her_treatment_all_inst(delta_h, T, tau_h, t)\n",
    "    graph_sim(sim_times, T_sim)\n",
    "    graph_dox(sim_times, dox)\n",
    "    graph_her(sim_times, her)\n",
    "    \n",
    "    \n",
    "\n",
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"  ## potential bug fix for slice, don't know if it matters anymore after solving divergence\n",
    "\n",
    "class exp_growth_model(growth_model):\n",
    "\n",
    "    def simulate(self, r, delta_d, delta_h, tau_d, tau_h, times=None):\n",
    "        if times is None: times = self._times        \n",
    "        return self._simulate([r, delta_d, delta_h, tau_d, tau_h], times)\n",
    "    \n",
    "    def dTdt(self, t, T, params): \n",
    "        T.clip(min=0) #logically \n",
    "        r, delta_d, delta_h, tau_d, tau_h = [x for x in params]\n",
    "        Sd = dox_treatment_all_inst(delta_d, T, tau_d, t)  #concentration is independent of volume\n",
    "        Sh = her_treatment_all_inst(delta_h, T, tau_h, t)\n",
    "        return (r - Sd - Sh)*T\n",
    "    \n",
    "    \n",
    "    def backward(self, T_obs, sigmas):\n",
    "        with pm.Model() as self.exp_mod:\n",
    "            r_lower = 0.03\n",
    "            r_upper = 0.07\n",
    "            delta_d_lower = 0\n",
    "            delta_d_upper = 5\n",
    "            delta_h_lower = 0\n",
    "            delta_h_upper = 0.1\n",
    "            tau_d_lower = 0\n",
    "            tau_d_upper = 8\n",
    "            tau_h_lower = -0.1\n",
    "            tau_h_upper = 0.05\n",
    "\n",
    "            r = pm.Uniform('r', lower=r_lower, upper=r_upper)           \n",
    "            delta_d = pm.Uniform('delta_d', lower=delta_d_lower, upper=delta_d_upper)\n",
    "            delta_h = pm.Uniform('delta_h', lower=delta_h_lower, upper=delta_h_upper)\n",
    "            tau_d = pm.Uniform('tau_d', lower=tau_d_lower, upper=tau_d_upper)\n",
    "            tau_h = pm.Uniform('tau_h', lower=tau_h_lower, upper=tau_h_upper)\n",
    "\n",
    "            self.param_list=['r','delta_d','delta_h','tau_d','tau_h']\n",
    "            @as_op(itypes=[tt.dscalar, tt.dscalar, tt.dscalar, tt.dscalar, tt.dscalar], otypes=[tt.dmatrix]) \n",
    "            def th_forward_model(r, delta_d, delta_h, tau_d, tau_h):\n",
    "                th_states = self.simulate(r, delta_d, delta_h, tau_d, tau_h)\n",
    "                return th_states\n",
    "            \n",
    "            forward = th_forward_model(r, delta_d, delta_h, tau_d, tau_h)\n",
    "            \n",
    "            T = pm.Normal('T', mu=forward, sigma = sigmas, observed=T_obs)\n",
    "\n",
    "            # Initial points for each of the chains\n",
    "            np.random.seed(123)\n",
    "            n_chains = 4\n",
    "            startsmc=[{'r':np.random.uniform(r_lower, r_upper), \n",
    "                       #'K':np.random.uniform(K_lower, K_upper), \n",
    "                       #'A':np.random.uniform(A_lower, A_upper),\n",
    "                       'delta_d':np.random.uniform(delta_d_lower, delta_d_upper),\n",
    "                       'delta_h':np.random.uniform(delta_h_lower, delta_h_upper),\n",
    "                       'tau_d':np.random.uniform(tau_d_lower, tau_d_upper),\n",
    "                       'tau_h':np.random.uniform(tau_h_lower, tau_h_upper),\n",
    "                      } for _ in range(n_chains)]\n",
    "            num_samples = 200\n",
    "            num_tune = int(num_samples/5)\n",
    "            self.trace = pm.sample(num_samples, tune=num_tune, chains = n_chains, cores=1, start=startsmc)\n",
    "            #pm.traceplot(self.trace) \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_growth_model(growth_model):  \n",
    "    \n",
    "    def simulate(self, r, K, delta_d, delta_h, tau_d, tau_h, times=None):\n",
    "        if times is None: times = self._times        \n",
    "        return self._simulate([r, K, delta_d, delta_h, tau_d, tau_h], times)\n",
    "    \n",
    "    def dTdt(self, t, T, params):\n",
    "        r, K, delta_d, delta_h, tau_d, tau_h = [x for x in params]             \n",
    "        Sd = dox_treatment_all_inst(delta_d, T, tau_d, t)\n",
    "        Sh = her_treatment_all_inst(delta_h, T, tau_h, t)\n",
    "        return  (r*(1-T/K) - Sh - Sd)*T\n",
    "    \n",
    "    def backward(self, T_obs, sigmas):\n",
    "        with pm.Model() as self.log_mod:\n",
    "            self.param_list = ['r', 'K', 'delta_d', 'delta_h', 'tau_d', 'tau_h']\n",
    "            r_lower = 0.03\n",
    "            r_upper = 0.07\n",
    "            K_lower = 200\n",
    "            K_upper = 3000\n",
    "            delta_d_lower = 0\n",
    "            delta_d_upper = 0.4\n",
    "            delta_h_lower = 0\n",
    "            delta_h_upper = 0.1\n",
    "            tau_d_lower = 0\n",
    "            tau_d_upper = 8\n",
    "            tau_h_lower = 0\n",
    "            tau_h_upper = 0.01\n",
    "\n",
    "            r = pm.Uniform('r', lower=r_lower, upper=r_upper)\n",
    "            K = pm.Uniform('K', lower=K_lower, upper=K_upper)\n",
    "            delta_d = pm.Uniform('delta_d', lower=delta_d_lower, upper=delta_d_upper)\n",
    "            delta_h = pm.Uniform('delta_h', lower=delta_h_lower, upper=delta_h_upper)\n",
    "            tau_d = pm.Uniform('tau_d', lower=tau_d_lower, upper=tau_d_upper)\n",
    "            tau_h = pm.Uniform('tau_h', lower=tau_h_lower, upper=tau_h_upper)\n",
    "\n",
    "            @as_op(itypes=[tt.dscalar, tt.dscalar, tt.dscalar, tt.dscalar, tt.dscalar, tt.dscalar], otypes=[tt.dmatrix]) \n",
    "            def th_forward_model(r, K, delta_d, delta_h, tau_d, tau_h):\n",
    "                th_states = self.simulate(r, K, delta_d, delta_h, tau_d, tau_h)\n",
    "                return th_states\n",
    "            \n",
    "            forward = th_forward_model(r, K, delta_d, delta_h, tau_d, tau_h)\n",
    "            \n",
    "            T = pm.Normal('T', mu=forward, sigma = sigmas, observed=T_obs)\n",
    "\n",
    "            # Initial points for each of the chains\n",
    "            np.random.seed(123)\n",
    "            n_chains = 4\n",
    "            startsmc=[{'r':np.random.uniform(r_lower, r_upper), \n",
    "                       'K':np.random.uniform(K_lower, K_upper), \n",
    "                       'delta_d':np.random.uniform(delta_d_lower, delta_d_upper),\n",
    "                       'delta_h':np.random.uniform(delta_h_lower, delta_h_upper),\n",
    "                       'tau_d':np.random.uniform(tau_d_lower, tau_d_upper),\n",
    "                       'tau_h':np.random.uniform(tau_h_lower, tau_h_upper),\n",
    "                      } for _ in range(n_chains)]\n",
    "            num_samples = 200\n",
    "            num_tune = int(num_samples/5)\n",
    "            self.trace = pm.sample(num_samples, tune=num_tune, chains = n_chains, cores=1, start=startsmc)\n",
    "            #pm.traceplot(self.trace) \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 200 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "CompoundStep\n",
      ">Slice: [tau_h]\n",
      ">Slice: [tau_d]\n",
      ">Slice: [delta_h]\n",
      ">Slice: [delta_d]\n",
      ">Slice: [r]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [01:53<00:00,  2.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [02:56<00:00,  1.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [02:08<00:00,  1.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [01:54<00:00,  2.09it/s]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Only 200 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "CompoundStep\n",
      ">Slice: [tau_h]\n",
      ">Slice: [tau_d]\n",
      ">Slice: [delta_h]\n",
      ">Slice: [delta_d]\n",
      ">Slice: [K]\n",
      ">Slice: [r]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [02:08<00:00,  1.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [02:08<00:00,  1.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [02:15<00:00,  1.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [02:11<00:00,  1.83it/s]\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "exp2 = exp_growth_model(ts,Ts[:,0])\n",
    "exp2.backward(Ts,sigmas)\n",
    "\n",
    "log2 = logistic_growth_model(ts,Ts[:,0])\n",
    "log2.backward(Ts,sigmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid\\Anaconda3\\lib\\site-packages\\pymc3\\stats.py:168: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.stack(logp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAIC</th>\n",
       "      <th>pWAIC</th>\n",
       "      <th>dWAIC</th>\n",
       "      <th>weight</th>\n",
       "      <th>SE</th>\n",
       "      <th>dSE</th>\n",
       "      <th>var_warn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1374.72</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>23.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1374.92</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.45</td>\n",
       "      <td>24.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WAIC pWAIC dWAIC weight     SE   dSE var_warn\n",
       "1  1374.72  0.99     0   0.55  23.69     0        0\n",
       "0  1374.92  1.54   0.2   0.45  24.38  2.85        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mod = exp2.exp_mod\n",
    "exp_mod.name = 'exponential'\n",
    "log_mod = log2.log_mod\n",
    "log_mod.name = 'logarithmic'\n",
    "\n",
    "\n",
    "df_comp_WAIC = pm.compare({exp2.exp_mod: exp2.trace, log2.log_mod: log2.trace})\n",
    "df_comp_WAIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare using leave one out cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid\\Anaconda3\\lib\\site-packages\\pymc3\\stats.py:300: UserWarning: Estimated shape parameter of Pareto distribution is\n",
      "        greater than 0.7 for one or more samples.\n",
      "        You should consider using a more robust model, this is because\n",
      "        importance sampling is less likely to work well if the marginal\n",
      "        posterior and LOO posterior are very different. This is more likely to\n",
      "        happen with a non-robust model and highly influential observations.\n",
      "  happen with a non-robust model and highly influential observations.\"\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOO</th>\n",
       "      <th>pLOO</th>\n",
       "      <th>dLOO</th>\n",
       "      <th>weight</th>\n",
       "      <th>SE</th>\n",
       "      <th>dSE</th>\n",
       "      <th>shape_warn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1374.73</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>23.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1375.06</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>24.37</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LOO  pLOO  dLOO weight     SE   dSE shape_warn\n",
       "1  1374.73  0.99     0   0.58  23.69     0          1\n",
       "0  1375.06  1.61  0.33   0.42  24.37  2.84          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_comp_LOO = pm.compare({exp2.exp_mod: exp2.trace, log2.log_mod: log2.trace}, ic='LOO')\n",
    "df_comp_LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mod = exp2.exp_mod\n",
    "exp_mod.name = 'exponential'\n",
    "log_mod = log2.log_mod\n",
    "log_mod.name = 'logarithmic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAIC</th>\n",
       "      <th>pWAIC</th>\n",
       "      <th>dWAIC</th>\n",
       "      <th>weight</th>\n",
       "      <th>SE</th>\n",
       "      <th>dSE</th>\n",
       "      <th>var_warn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>logarithmic</td>\n",
       "      <td>1374.72</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>23.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>exponential</td>\n",
       "      <td>1374.92</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.45</td>\n",
       "      <td>24.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                WAIC pWAIC dWAIC weight     SE   dSE var_warn\n",
       "logarithmic  1374.72  0.99     0   0.55  23.69     0        0\n",
       "exponential  1374.92  1.54   0.2   0.45  24.38  2.85        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp_WAIC = pm.compare({exp_mod: exp2.trace, log_mod: log2.trace})\n",
    "df_comp_WAIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements\n",
    "#each model in models has been instantiated and fitted\n",
    "#models is a dic that has the model name as key and model object as value\n",
    "\n",
    "#def validate_and_compare(models):\n",
    "#    print("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
